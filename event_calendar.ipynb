{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84dacf4d-09ee-49a4-928e-59d23e05d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run headless Chrome, optional\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15addc9-f9e1-45e9-9b93-a8fd1c8524cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af3aeeb-8984-4f95-a7fc-c3717dfaeeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTimeOut LA\\nDiscover LA\\nWE Like LA\\nSecret Los Angeles\\nKCRW Events\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TimeOut LA\n",
    "Discover LA\n",
    "WE Like LA\n",
    "Secret Los Angeles\n",
    "KCRW Events\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c719ff2-7f05-414e-b4ba-40fd0d1d5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_more_events2(driver):\n",
    "    \"\"\"\n",
    "    This loading function\n",
    "    jumps down to the viewMore div and moves slightly up the screen,\n",
    "    which seems to work for timeout\n",
    "    \"\"\"\n",
    "    for _ in range(20): # only try 20 times for now\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            element = WebDriverWait(driver, 20).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"div[class*='viewMore']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "            driver.execute_script(f\"window.scrollBy(0, -100);\")\n",
    "        except:\n",
    "            print(\"can't scoll anymore\")\n",
    "            break\n",
    "    return(True)\n",
    "    \n",
    "# def load_more_events1(driver):\n",
    "#     \"\"\"\n",
    "#     this old loading function\n",
    "#     moved slowly down the page\n",
    "#     because jumping down caused problems\n",
    "#     \"\"\"\n",
    "#     # Function to scroll down the page\n",
    "#     def scroll_down(driver):\n",
    "#         # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#          driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "#          new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#          return(new_height)\n",
    "\n",
    "\n",
    "#     # Scroll 60% of the way to start\n",
    "#     total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#     scroll_height = total_height * 0.40\n",
    "#     driver.execute_script(f\"window.scrollBy(0, {scroll_height});\")\n",
    "#     time.sleep(3)\n",
    "#     height = total_height\n",
    "\n",
    "#     # Initialize a list to store the article URLs\n",
    "#     article_urls = list()\n",
    "    \n",
    "#     # Scroll and collect article URLs\n",
    "#     SCROLL_PAUSE_TIME = 1\n",
    "#     max_attempts = 50  # Maximum number of scrolls\n",
    "#     attempts = 0\n",
    "#     num_hrefs = 0\n",
    "\n",
    "#     # Get all the events \n",
    "#     while True:\n",
    "#         # Scroll down the page\n",
    "#         \"\"\"\n",
    "#         This strange scrolling + checking issue\n",
    "#         Is because I can't find a good way to get the \n",
    "#         feed to continually refresh as the bot\n",
    "#         scrolls down the page -- if I scroll too fast\n",
    "#         it doesn't update and we get stuck on the footer\n",
    "#         and don't refresh, too slow and it takes forever\n",
    "#         to run.\n",
    "    \n",
    "#         Currently it moves down 500px, and checks \n",
    "#         every 50 scrolls if new content has emerged.\n",
    "#         I'm sure there is a way to simple add a conditional\n",
    "#         but MOVING ON.\n",
    "#         \"\"\"\n",
    "#         new_height = scroll_down(driver)\n",
    "#         # print(\"#\", attempts)\n",
    "        \n",
    "#         # Wait to load the page\n",
    "#         time.sleep(SCROLL_PAUSE_TIME)\n",
    "        \n",
    "#         # Only check every 50 scrolls\n",
    "#         attempts += 1\n",
    "#         if attempts % 50 != 0:\n",
    "#             continue\n",
    "#         # Collect new titles\n",
    "#         else:\n",
    "#             ## THIS WILL BREAK NOW:\n",
    "#             added, article_urls = collect_titles(article_urls, driver)\n",
    "#             if added == 0:\n",
    "#                 break\n",
    "    \n",
    "#     print(len(article_urls), 'total articles found.')\n",
    "\n",
    "#     return(True)\n",
    "\n",
    "\n",
    "    \n",
    "def collect_titles(driver):\n",
    "    # Get articles on the page\n",
    "    title_divs = driver.find_elements(By.XPATH, '//*[contains(@class, \"title\")]')\n",
    "    article_urls = []\n",
    "\n",
    "    # Collect URLs from within these divs\n",
    "    for title in title_divs:\n",
    "        links = title.find_elements(By.TAG_NAME, 'a')\n",
    "        for link in links:\n",
    "            href = link.get_attribute('href')\n",
    "            if href and 'timeout.com/los-angeles/' in href:\n",
    "                if href not in article_urls:\n",
    "                    article_urls.append(href)\n",
    "    print(len(article_urls), \"new articles\")\n",
    "\n",
    "    return(article_urls)\n",
    "\n",
    "def pull_tout_event_info(driver, article_urls):\n",
    "    \n",
    "    event_title = []\n",
    "    event_description = []\n",
    "    event_date = []\n",
    "    event_time = []\n",
    "    event_location = []\n",
    "    event_price = []\n",
    "    event_urls = []\n",
    "    \n",
    "    for event_url in article_urls:\n",
    "        # print(event_url)\n",
    "        driver.get(event_url)\n",
    "        time.sleep(2)\n",
    "    \n",
    "        title = event_url.split('/')[-1].replace(\"-\",\" \").title()\n",
    "        # event_title.append(title)\n",
    "        \n",
    "        try:\n",
    "            details_sections = driver.find_element(By.CSS_SELECTOR, 'section[data-section-name=\"review\"]')\n",
    "            descr_txt = details_sections.text\n",
    "        except:\n",
    "            descr_txt = \"None.\"\n",
    "        try:\n",
    "            occurrence_section = driver.find_element(By.CSS_SELECTOR, 'section[data-section-name=\"occurrences\"]')\n",
    "            zones = occurrence_section.find_element(By.CLASS_NAME, 'zoneItems')\n",
    "            child_divs = zones.find_elements(By.XPATH, './div')\n",
    "            timestamps = []\n",
    "            venues = []\n",
    "            prices = []\n",
    "            for entry in child_divs:\n",
    "                time_element = entry.find_element(By.TAG_NAME, 'time')\n",
    "                timestamp = time_element.get_attribute('datetime') \n",
    "                timestamps.append(timestamp)\n",
    "    \n",
    "                try:\n",
    "                    venue = entry.find_element(By.XPATH, './/span[contains(@class, \"venueName\")]/a').text\n",
    "                    venues.append(venue)\n",
    "                except:\n",
    "                    venues.append(\"unknown\")\n",
    "    \n",
    "                try:\n",
    "                    price = entry.find_element(By.XPATH, './/div[contains(@class, \"price\")]').text\n",
    "                    prices.append(price)\n",
    "                except:\n",
    "                    prices.append(\"unknown\")\n",
    "        except:\n",
    "            timestamps = [\"unknown\"]; venues = [\"unknown\"]; prices = [\"unknown\"]\n",
    "            \n",
    "            \n",
    "        for i in range(len(timestamps)):\n",
    "            if len(timestamps) > 1:\n",
    "                event_title.append(title+f\" (Day {i+1}\")\n",
    "            else:\n",
    "                event_title.append(title)\n",
    "            event_date.append(timestamps[i])\n",
    "            event_time.append(timestamps[i])\n",
    "            event_location.append(venues[i])\n",
    "            event_price.append(prices[i])\n",
    "            event_description.append(descr_txt)\n",
    "            event_urls.append(event_url)\n",
    "\n",
    "    p = pd.DataFrame({\"Name\":event_title, \n",
    "                      \"Description\":event_description,\n",
    "                      \"Date\":event_date,\n",
    "                      \"Time\":event_time,\n",
    "                      \"Location\":event_location,\n",
    "                      \"Price\": event_price,\n",
    "                      \"URL\":event_urls})\n",
    "    return(p)\n",
    "\n",
    "def pull_timeout_calendar():\n",
    "    # Create a new instance of the Chrome driver\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    \n",
    "    months = ['august','september','october','november','december']\n",
    "    \n",
    "    events_pd = pd.DataFrame({'Name':[],\n",
    "                              'Description':[],\n",
    "                              'Date': [],\n",
    "                              'Time':[],\n",
    "                              'Location':[],\n",
    "                              'Price':[],\n",
    "                              'URL':[]})\n",
    "    for month in months:\n",
    "        print(month)\n",
    "    \n",
    "        # Navigate to the Time Out Los Angeles page\n",
    "        url = f\"https://www.timeout.com/los-angeles/things-to-do/{month}-events-calendar\"\n",
    "        try:\n",
    "            driver.get(url)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "        load_more_events2(driver)\n",
    "        \n",
    "        article_urls = collect_titles(driver)\n",
    "        \n",
    "        p = pull_tout_event_info(driver, article_urls)\n",
    "    \n",
    "        events_pd = pd.concat([events_pd,p])\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d956f770-845b-476f-9b15-78cd53b8f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discover Los Angeles\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def get_links(driver):\n",
    "    return(\n",
    "        driver.find_elements(By.XPATH, \"//a[not(contains(@style, 'display:none')) and not(contains(@style, 'visibility:hidden'))]\")\n",
    "    )\n",
    "def load_more_days(driver):\n",
    "    for _ in range(5): # only try 5 times for now\n",
    "        try:\n",
    "            time.sleep(3)\n",
    "            element = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//*[contains(@id, 'load-more')]\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "            driver.execute_script(f\"window.scrollBy(0, -100);\")\n",
    "            element.click()\n",
    "        except:\n",
    "            print(\"can't load anymore.\")\n",
    "            break\n",
    "        try:\n",
    "            element = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"img[name^='ajax-loader']\")))\n",
    "            # Takes a long time to load...\n",
    "            element = WebDriverWait(driver, 1000).until(\n",
    "                EC.invisibility_of_element_located((By.CSS_SELECTOR, \"img[name^='ajax-loader']\")))\n",
    "            print(\"The loading GIF has disappeared.\")\n",
    "        except:\n",
    "            print(\"The loading GIF is still visible or the timeout was reached.\")\n",
    "            break\n",
    "    return(True)\n",
    "\n",
    "def load_more_daily_events(driver):\n",
    "    anchors = get_links(driver)\n",
    "    print(\"links before:\", len(anchors))\n",
    "    time.sleep(3)\n",
    "    elements = driver.find_elements(By.CSS_SELECTOR, \"ul\")\n",
    "    for e in elements:\n",
    "        if 'item' in e.text:\n",
    "            item_element = e.find_element(By.XPATH, \".//*[contains(text(), 'item')]\")\n",
    "            driver.execute_script(\"arguments[0].click();\", item_element)\n",
    "            time.sleep(1)\n",
    "    anchors = get_links(driver)\n",
    "    print(\"links after:\",len(links))\n",
    "\n",
    "    return(True)\n",
    "\n",
    "def collect_links(driver):\n",
    "    anchors = get_links(driver)\n",
    "    visited_links = list(set(visited_links))\n",
    "    c = 0\n",
    "    visited_links = []\n",
    "    for a in anchors:\n",
    "        if c % 100 == 0:\n",
    "            print(c)\n",
    "        c += 1\n",
    "        link = a.get_attribute('href')\n",
    "        \n",
    "        if not link:\n",
    "            continue\n",
    "        elif ('https://www.discoverlosangeles.com/event/' not in link) or link in visited_links:\n",
    "            continue\n",
    "        else:\n",
    "            visited_links.append(link)\n",
    "    print(len(visited_links),\" events found.\")\n",
    "\n",
    "    return(visited_links)\n",
    "\n",
    "def collect_event_info(driver,visited_links):\n",
    "\n",
    "    name_list = []\n",
    "    price_list = []\n",
    "    date_list = []\n",
    "    time_list = []\n",
    "    location_list = []\n",
    "    desc_list = []\n",
    "    for link in visited_links:\n",
    "        name = link.split('/')[-1].replace('-',' ').strip().title()\n",
    "        # print(link)\n",
    "        # print(name)\n",
    "        driver.get(link)\n",
    "    \n",
    "        price = None\n",
    "        date = None\n",
    "        time_ = None\n",
    "    \n",
    "        ## Get event details\n",
    "        try:\n",
    "            info = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class*='dla-information']\"))\n",
    "        )\n",
    "            info = info.text\n",
    "            info = ' '.join(info.split()).strip()\n",
    "    \n",
    "            for fact in info.split(\"|\"):\n",
    "                if '$' in fact:\n",
    "                    price = '$'+fact.split(\"$\")[-1]\n",
    "                elif 'PM' in fact or 'AM' in fact:\n",
    "                    time_ = ' '.join(fact.split())\n",
    "                elif '2024' in fact:\n",
    "                    date = ' '.join(fact.split())\n",
    "                    ## TODO: There are date ranges in here!\n",
    "                    if \"-\" in date:\n",
    "                        date = \" \".join(date.split(\"-\")[0].split())\n",
    "                    else:\n",
    "                        date = date.split(\", 2024\")[0]\n",
    "            # print(\"Price:\", price)\n",
    "            # print(\"Date:\", date)\n",
    "            # print(\"Time:\", time)\n",
    "        except:\n",
    "            # print(\"no info\")\n",
    "            info = None\n",
    "    \n",
    "        ## Get location\n",
    "        try:\n",
    "            location = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"span[class*='dla-venue']\"))\n",
    "        )\n",
    "            location = location.text\n",
    "            location = ' '.join(location.split()).strip()\n",
    "            # print(\"LOCATION: \",location)\n",
    "        except:\n",
    "            # print(\"no location\")\n",
    "            location = None\n",
    "    \n",
    "        try:\n",
    "            description = driver.find_element(By.XPATH, \"//div[@class='dla-txt']\")\n",
    "            # description = location.text\n",
    "            # description = ' '.join(description.split()).strip()\n",
    "            description = description.text\n",
    "            # print(\"DESC: \",description)\n",
    "        except:\n",
    "            # print(\"no desc\")\n",
    "            description = None\n",
    "    \n",
    "        name_list.append(name)\n",
    "        price_list.append(price)\n",
    "        date_list.append(date)\n",
    "        time_list.append(time_)\n",
    "        location_list.append(location)\n",
    "        desc_list.append(description)\n",
    "    \n",
    "    p = pd.DataFrame({\n",
    "        \"Name\":name_list,\n",
    "        \"Date\":date_list,\n",
    "        \"Description\":desc_list,\n",
    "        \"Time\":time_list,\n",
    "        \"Location\":location_list,\n",
    "        \"Price\":price_list,\n",
    "        \"URL\":visited_links\n",
    "    })\n",
    "    return(p)\n",
    "\n",
    "def pull_dla_calendar():\n",
    "    url = 'https://www.discoverlosangeles.com/events'\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    load_more_days(driver)\n",
    "    load_more_daily_events(driver)\n",
    "    visited_links = collect_links(driver)\n",
    "    p = collect_event_info(driver, visited_links)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e1d36-90cb-43ff-953d-873aafd2b010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeout...\n",
      "august\n",
      "can't scoll anymore\n",
      "95 new articles\n",
      "september\n",
      "can't scoll anymore\n",
      "64 new articles\n"
     ]
    }
   ],
   "source": [
    "print(\"timeout...\")\n",
    "p1 = pull_timeout_calendar()\n",
    "print(\"discovery la...\")\n",
    "p2 = pull_dla_calendar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f151d-0279-4573-9513-ae8042be5ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
